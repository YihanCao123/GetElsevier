{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bit1e709d27370248668c5cb1cb9452c666",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elsevier Database "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Needed Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import bs4\n",
    "from lxml import etree\n",
    "import requests\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Global URL and Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_url = 'https://www.sciencedirect.com/search/advanced?tak=Coronavirus%20OR%20%22Corona%20virus%22%20OR%20%222019-nCoV%22%20OR%20%22SADS-CoV%22%20OR%20%22SARS-CoV%22%20OR%20%22MERS-CoV%22%20OR%20%E2%80%9CSevere%20Acute%20Respiratory%20Syndrome%E2%80%9D%20OR%20%E2%80%9CMiddle%20East%20Respiratory%20Syndrome%E2%80%9D&articleTypes=REV%2CFLA&show=100&ent=true&years=2020%2C2019&lastSelectedFacet=years'\n",
    "headers = {\n",
    "     'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.87 Safari/537.36'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define getelsevier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_list = []\n",
    "paper_href = []\n",
    "def getelsevier(url, headers, page):\n",
    "    for i in range(page):\n",
    "        page_url = global_url+'&offset='+str(page*100)\n",
    "        try:\n",
    "            response = requests.get(url, headers = headers)\n",
    "            print('successfully get')\n",
    "        except:\n",
    "            pass\n",
    "        global_html = etree.HTML(response.content)\n",
    "        page_paper_list = global_html.xpath('/html/body/div/div/div/div/div/div/div/section/div/div[2]/main/div/div[2]/div[2]/ol/li/div/div/h2/span/a/text()')\n",
    "        paper_list.append(page_paper_list)#print titles\n",
    "        page_paper_href = global_html.xpath('/html/body/div/div/div/div/div/div/div/section/div/div[2]/main/div/div[2]/div[2]/ol/li/div/div/h2/span/a/@href')\n",
    "        paper_href.append(page_paper_href)\n",
    "        print('Getelsevier end.')\n",
    "    return paper_list, paper_href"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defne getpaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = []\n",
    "title_list = []\n",
    "abstract_list = []\n",
    "main_authors = []\n",
    "doi_list = []\n",
    "keyword_list = []\n",
    "paper = []\n",
    "def getpaper(paper_href, headers, timeout = None):\n",
    "    base_url = 'https://www.sciencedirect.com'\n",
    "    for single_href in paper_href:\n",
    "        com_url = base_url + single_href # should all be strings\n",
    "        try:\n",
    "            single_resp = requests.get(com_url, headers = headers, timeout=30)\n",
    "            print('successfully get')\n",
    "            single_html = etree.HTML(single_resp.content)\n",
    "            single_title = single_html.xpath('//span[@class=\"title-text\"]/text()')[0]\n",
    "            single_abstract = single_html.xpath('//div[@class=\"abstract author\"]/div/p/text()')\n",
    "            single_author = single_html.xpath('//div[@class=\"author-group\"]/a/span/span/text()')\n",
    "            single_doi = single_html.xpath('//div[@class=\"DoiLink\"]/a/text()')[0]\n",
    "            single_keyword = []\n",
    "            for keyword in range(1,4):\n",
    "                keyword_xpath = '//div[@class=\"Keywords u-font-serif\"]/div/div['+str(keyword)+']/span/text()'\n",
    "                single_keyword.append(single_html.xpath(keyword_xpath)[0])\n",
    "            single_paper = {\"url\":com_url, \"title\":single_title, \"abstract\": \" \".join(single_abstract), \"author\":single_author, \"doi\":single_doi, \"keyword\": single_keyword}\n",
    "            paper.append(single_paper)\n",
    "            print('complete')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "successfully get\nsuccessfully get\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\nsuccessfully get\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\nsuccessfully get\ncomplete\nsuccessfully get\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\nsuccessfully get\ncomplete\nsuccessfully get\nsuccessfully get\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\nsuccessfully get\ncomplete\n"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    global_url = 'https://www.sciencedirect.com/search/advanced?tak=Coronavirus%20OR%20%22Corona%20virus%22%20OR%20%222019-nCoV%22%20OR%20%22SADS-CoV%22%20OR%20%22SARS-CoV%22%20OR%20%22MERS-CoV%22%20OR%20%E2%80%9CSevere%20Acute%20Respiratory%20Syndrome%E2%80%9D%20OR%20%E2%80%9CMiddle%20East%20Respiratory%20Syndrome%E2%80%9D&articleTypes=REV%2CFLA&show=100&ent=true&years=2020%2C2019&lastSelectedFacet=years'\n",
    "    headers = {\n",
    "        'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.87 Safari/537.36'\n",
    "    }\n",
    "    ncov_paper_list, ncov_paper_href = getelsevier(url = global_url, headers = headers, page=2)#Because there are only 2 pages about ncovpaper, so we set 2 here.\n",
    "    paper_json = getpaper(ncov_paper_href[0], headers = headers, timeout = 5)\n",
    "    with open(\"C:/Users/Administrator/Desktop/Intership/data.json\",\"w\") as dump_f: #output\n",
    "        json.dump(paper_json,dump_f)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}